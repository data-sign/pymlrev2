## 8.7 문서 군집화  
### 개념
- 문서 군집화(Document Clustering) : 비슷한 텍스트 구성의 문서를 군집화하는 것
- 동일한 군집의 문서를 같은 카테고리로 분류할 수 있어 텍스트 분류 기반 문서 분류와 유사하지만 문서 군집화는 카테고리 라벨 값을 가진 학습 데이터가 불필요한 비지도학습 방법 
### 실습 - Opinion Review 데이터세트
#### 데이터 
- UCI 머신러닝 리포지토리에 있는 opinion review 데이터세트 
- 51개 텍스트 파일, Tripadvisor(호텔), Edmunds.com(자동차), Amazon.com(전자제품) 사이트에서 가져온 리뷰 문서이며 각 문서당 100개의 문장이 있음. 
- https://archive.ics.uci.edu/dataset/191/opinosis+opinion+frasl+review
1. 데이터 로드 : 51개 텍스트 파일 합친 데이터프레임 생성
2. 피처 벡터화 
    - tokenizer : Lemmatization 구현 함수
    - ngram : (1, 2)
    - TfdfVectorizer 로 변환 
3. 군집화 : Kmeans 이용해 5개 집합, 3개 집합으로 군집화 
    - 전자제품(네비게이션, 아이팟, 킨들, 랩탑 등), 자동차, 호텔 

```python
from nltk.stem import WordNetLemmatizer
import nltk
import string

remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)
lemmar = WordNetLemmatizer()

# 입력으로 들어온 token단어들에 대해서 lemmatization 어근 변환. 
def LemTokens(tokens):
    return [lemmar.lemmatize(token) for token in tokens]

# TfidfVectorizer 객체 생성 시 tokenizer인자로 해당 함수를 설정하여 lemmatization 적용
# 입력으로 문장을 받아서 stop words 제거-> 소문자 변환 -> 단어 토큰화 -> lemmatization 어근 변환. 
def LemNormalize(text):
    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))

## TF-IDF 변환 
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english' , \
                             ngram_range=(1,2), min_df=0.05, max_df=0.85 )

#opinion_text 컬럼값으로 feature vectorization 수행
feature_vect = tfidf_vect.fit_transform(document_df['opinion_text'])

## KMeans 수행 
from sklearn.cluster import KMeans

# 5개 집합으로 군집화 수행. 예제를 위해 동일한 클러스터링 결과 도출용 random_state=0 
km_cluster = KMeans(n_clusters=5, max_iter=10000, random_state=0)
km_cluster.fit(feature_vect)
cluster_label = km_cluster.labels_
cluster_centers = km_cluster.cluster_centers_

```

#### 군집별 핵심 단어 추출
- 각 군집의 핵심 단어 추출
- clusters_centers_ : 군집을 구성하는 단어 피처가 군집의 중심을 기준으로 얼마나 가까운 위치에 있는지 나타냄 
    - 행 : 개별 군집, 열 : 개별 피처, 값 : 개별 군집 내 상대 위치 값( like 좌표 값)
    - 0~1의 값을 가지며, 1에 가까울수록 중심과 가까움. 
- ndarray의 argsort()[:,::-1]를 이용해 배열 내 큰 값 가지는 위치 인덱스 반환 
- 배열 내 가장 값이 큰 인덱스 추출 후, 해당 인덱스로 핵심 단어 이름과 상대 위치 값 추출 cluster_details 딕셔너리에 저장 